{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(''))))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# classifiers  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# sampling \n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "from utils.data_extract_utils import get_home_credit_data, extract_zip, extract_features_from_bureau, EXTRACTRED_BUREAU_COLUMNS, extract_features_from_installments_payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download, and extract data from dropbox into memory. \n",
    "data = get_home_credit_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_temp_data(data):\n",
    "    ## combine train and test set\n",
    "    train_test = data['application_train'].append(data['application_test']).reset_index()\n",
    "\n",
    "    # join tables: bureau, bureau_balance - 1 min to execute\n",
    "    bb = extract_features_from_bureau(data['bureau'], data['bureau_balance'])\n",
    "    ip = extract_features_from_installments_payments(data['installments_payments'])\n",
    "\n",
    "    # Join ID same datatype\n",
    "    train_test['SK_ID_CURR'] = train_test['SK_ID_CURR'].astype('Int64')\n",
    "    bb.index = bb.index.astype('Int64')\n",
    "    ip.index = ip.index.astype('Int64')\n",
    "\n",
    "    # Join Bureau(s) and Application tables\n",
    "    df = train_test.join([bb, ip])\n",
    "    \n",
    "    # drop index column generated by groupby\n",
    "    df.drop(['index'], axis=1, inplace=True)\n",
    "    \n",
    "    # clean memory \n",
    "    del bb\n",
    "    gc.collect()\n",
    "    \n",
    "    # preprocess \n",
    "    ## DAYS_EMPLOYED\n",
    "    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)\n",
    "    df['DAYS_EMPLOYED'] = df['DAYS_EMPLOYED'].apply(lambda x: abs(x))\n",
    "\n",
    "    df['BIRTH_IN_YEARS'] = df['DAYS_BIRTH'].apply(lambda x: abs(x)/365)\n",
    "\n",
    "    # remove 4 instances\n",
    "    df = df.loc[df['CODE_GENDER'] != 'XNA', :]\n",
    "\n",
    "    # add new features \n",
    "    df['ALL_EXT_SOURCE_MEAN']=df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis = 1)\n",
    "    df['PAYMENT_RATE'] = df['AMT_ANNUITY']/df['AMT_CREDIT']\n",
    "    df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL']/df['CNT_FAM_MEMBERS']\n",
    "    df['INCOME_CREDIT_IN_PERCENTAGE '] = df['AMT_INCOME_TOTAL']/df['AMT_CREDIT']\n",
    "    df['ANNUITY_INCOME_IN_PERCENTAGE'] = df['AMT_ANNUITY']/df['AMT_INCOME_TOTAL']\n",
    "\n",
    "    ## label encoder for binary values\n",
    "    bin_features = ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']\n",
    "\n",
    "    replace_dict = {'CODE_GENDER': {'M': 0, 'F': 1},\n",
    "                    'FLAG_OWN_CAR': {'Y': 0, 'N': 1}, \n",
    "                    'FLAG_OWN_REALTY':{'Y': 0, 'N': 1} }\n",
    "    df.replace(replace_dict, inplace=True)\n",
    "    \n",
    "    # fix inf values\n",
    "    df['AMT_CREDIT_DEBT_RATIO'] = df['AMT_CREDIT_DEBT_RATIO'].apply(lambda x: x if ~np.isinf(x) else 0)\n",
    "    \n",
    "    # test ids\n",
    "    test_ids = df.loc[df['TARGET'].isnull(), 'SK_ID_CURR']\n",
    "    \n",
    "    # drop ids\n",
    "    df.drop(columns=['SK_ID_CURR'], axis=1, inplace=True)\n",
    "    \n",
    "    return df, test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, test_ids = get_temp_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 356251 entries, 0 to 356254\n",
      "Columns: 131 entries, TARGET to ANNUITY_INCOME_IN_PERCENTAGE\n",
      "dtypes: float64(115), int64(3), object(13)\n",
      "memory usage: 358.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 114)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = (df.loc[df['TARGET'].notnull(), :].drop(columns=['TARGET'], axis=1), \n",
    "        df.loc[df['TARGET'].notnull(), 'TARGET'])\n",
    "\n",
    "# test set for kaggle\n",
    "X_test = df.loc[df['TARGET'].isnull(), :].drop(columns=['TARGET'], axis=1)\n",
    "\n",
    "# columns for pipeline\n",
    "cat_cols = list(X.select_dtypes(include=object).columns)\n",
    "num_cols = list(X.select_dtypes(include=[int, float]).columns)\n",
    "len(cat_cols),len(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pipelines\n",
    "\n",
    "# one hot encoding \n",
    "categorical_pipe = Pipeline(steps=[\n",
    "    ('cat_imp', SimpleImputer(strategy='most_frequent', add_indicator=False)),\n",
    "  ('one_hot_encoder', OneHotEncoder(sparse=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# numerical \n",
    "numerical_pipe = Pipeline(steps=[\n",
    "    ('num_imp', SimpleImputer(strategy='median', add_indicator=False)),\n",
    "    (\"scale\", StandardScaler())  \n",
    "])\n",
    "\n",
    "\n",
    "# transform columns \n",
    "column_transformer = ColumnTransformer(transformers=[    \n",
    "    ('num_pip', numerical_pipe, num_cols),\n",
    "    ('cat_pipe', categorical_pipe, cat_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply preprocessing to X\n",
    "X_trans = column_transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smote sampling\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "X_sm, y_sm = smote.fit_resample(X_trans,y)\n",
    "\n",
    "# split data into k folds\n",
    "# sss = StratifiedShuffleSplit(n_splits=3, test_size=0.3, random_state=42)\n",
    "# score_val = []\n",
    "# for train_index, val_index in sss.split(X_sm, y_sm):\n",
    "#     # initalize model \n",
    "#     model = LogisticRegression(solver='lbfgs', random_state=42,max_iter=1000)\n",
    "#     # fit model \n",
    "#     model.fit(X_sm[train_index], y_sm[train_index])\n",
    "#     # test model\n",
    "#     score_val.append(balanced_accuracy_score(y_sm[val_index], model.predict(X_sm[val_index])))\n",
    "## takes about 6 min to execute ... 2 min per fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifaction report on training set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70    226145\n",
      "           1       0.70      0.71      0.70    226146\n",
      "\n",
      "    accuracy                           0.70    452291\n",
      "   macro avg       0.70      0.70      0.70    452291\n",
      "weighted avg       0.70      0.70      0.70    452291\n",
      "\n",
      "--------------------------------------------------------------\n",
      "classifaction report on validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.70      0.70     56537\n",
      "           1       0.70      0.71      0.71     56536\n",
      "\n",
      "    accuracy                           0.70    113073\n",
      "   macro avg       0.70      0.70      0.70    113073\n",
      "weighted avg       0.70      0.70      0.70    113073\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_sm, y_sm, test_size=0.2, random_state= 42, stratify=y_sm)\n",
    "logreg= LogisticRegression(solver='lbfgs', random_state=42,max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_train = logreg.predict(X_train)\n",
    "y_pred_val = logreg.predict(X_val)\n",
    "print('classifaction report on training set')\n",
    "print(classification_report(y_train, y_pred_train, labels=[0,1]))\n",
    "print('--------------------------------------------------------------')\n",
    "print('classifaction report on validation set')\n",
    "print(classification_report(y_val, y_pred_val, labels=[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
