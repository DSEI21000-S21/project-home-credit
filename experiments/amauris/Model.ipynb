{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(''))))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# classifiers  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# sampling \n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "from utils.data_extract_utils import get_home_credit_data, extract_zip, extract_features_from_bureau, EXTRACTRED_BUREAU_COLUMNS, extract_features_from_installments_payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download, and extract data from dropbox into memory. \n",
    "data = get_home_credit_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_temp_data(data):\n",
    "    ## combine train and test set\n",
    "    train_test = data['application_train'].copy().append(data['application_test']).reset_index()\n",
    "\n",
    "    # join tables: bureau, bureau_balance - 1 min to execute\n",
    "    bb = extract_features_from_bureau(data['bureau'], data['bureau_balance'])\n",
    "    ip = extract_features_from_installments_payments(data['installments_payments'])\n",
    "\n",
    "    # Join ID same datatype\n",
    "    train_test['SK_ID_CURR'] = train_test['SK_ID_CURR'].astype('Int64')\n",
    "    bb.index = bb.index.astype('Int64')\n",
    "    ip.index = ip.index.astype('Int64')\n",
    "\n",
    "    # Join Bureau(s) and Application tables\n",
    "    df = train_test.join([bb, ip])\n",
    "    df = train_test\n",
    "    \n",
    "    # drop index column generated by groupby\n",
    "    df.drop(['index'], axis=1, inplace=True)\n",
    "    \n",
    "    # clean memory \n",
    "    del bb\n",
    "    gc.collect()\n",
    "    \n",
    "    # preprocess \n",
    "    ## DAYS_EMPLOYED\n",
    "    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)\n",
    "    df['DAYS_EMPLOYED'] = df['DAYS_EMPLOYED'].apply(lambda x: abs(x))\n",
    "\n",
    "    df['BIRTH_IN_YEARS'] = df['DAYS_BIRTH'].apply(lambda x: abs(x)/365)\n",
    "\n",
    "    # remove 4 instances\n",
    "    df = df.loc[df['CODE_GENDER'] != 'XNA', :]\n",
    "\n",
    "    # add new features \n",
    "    df['ALL_EXT_SOURCE_MEAN'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis = 1)\n",
    "    df['PAYMENT_RATE'] = df['AMT_ANNUITY']/df['AMT_CREDIT']\n",
    "    df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL']/df['CNT_FAM_MEMBERS']\n",
    "    df['INCOME_CREDIT_IN_PERCENTAGE '] = df['AMT_INCOME_TOTAL']/df['AMT_CREDIT']\n",
    "    df['ANNUITY_INCOME_IN_PERCENTAGE'] = df['AMT_ANNUITY']/df['AMT_INCOME_TOTAL']\n",
    "\n",
    "    ## label encoder for binary values\n",
    "    bin_features = ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']\n",
    "\n",
    "    replace_dict = {'CODE_GENDER': {'M': 0, 'F': 1},\n",
    "                    'FLAG_OWN_CAR': {'Y': 0, 'N': 1}, \n",
    "                    'FLAG_OWN_REALTY':{'Y': 0, 'N': 1} }\n",
    "    df.replace(replace_dict, inplace=True)\n",
    "\n",
    "    # test ids\n",
    "    test_ids = df.loc[df['TARGET'].isnull(), 'SK_ID_CURR']\n",
    "    \n",
    "    # drop ids\n",
    "    df.drop(columns=['SK_ID_CURR'], axis=1, inplace=True)\n",
    "    \n",
    "    return df, test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, test_ids = get_temp_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ALL_EXT_SOURCE_MEAN', 0.8029775559676101],\n",
       " ['EXT_SOURCE_3', 0.6574052362122745],\n",
       " ['EXT_SOURCE_1', 0.6020921455180898],\n",
       " ['EXT_SOURCE_2', 0.5635826904343966],\n",
       " ['DAYS_EMPLOYED', 0.2952039165840869],\n",
       " ['DAYS_BIRTH', 0.2929482853977818],\n",
       " ['BIRTH_IN_YEARS', 0.29294828539768464],\n",
       " ['REGION_RATING_CLIENT_W_CITY', 0.2243342637607208],\n",
       " ['REGION_RATING_CLIENT', 0.21719343668979954],\n",
       " ['DAYS_LAST_PHONE_CHANGE', 0.21090175678596504],\n",
       " ['CODE_GENDER', 0.1970748734489275],\n",
       " ['DAYS_ID_PUBLISH', 0.18859657864381962],\n",
       " ['FLAG_EMP_PHONE', 0.18166909433252273],\n",
       " ['REG_CITY_NOT_WORK_CITY', 0.17986613979764166],\n",
       " ['FLOORSMAX_AVG', 0.17883519882839227],\n",
       " ['FLOORSMAX_MEDI', 0.17793947200777221],\n",
       " ['FLOORSMAX_MODE', 0.17567367050375474],\n",
       " ['FLAG_DOCUMENT_3', 0.16937130674957449],\n",
       " ['DAYS_REGISTRATION', 0.15876509686754345],\n",
       " ['AMT_GOODS_PRICE', 0.15688444651736286],\n",
       " ['REG_CITY_NOT_LIVE_CITY', 0.14933417407558774],\n",
       " ['REGION_POPULATION_RELATIVE', 0.1460455385294134],\n",
       " ['ELEVATORS_AVG', 0.14259932942154022],\n",
       " ['OWN_CAR_AGE', 0.14211414127172406],\n",
       " ['ELEVATORS_MEDI', 0.1412241627215555],\n",
       " ['FLOORSMIN_AVG', 0.13774276917016418],\n",
       " ['FLOORSMIN_MEDI', 0.13697012269369896],\n",
       " ['LIVINGAREA_AVG', 0.13508396127528452],\n",
       " ['LIVINGAREA_MEDI', 0.1341153293059249],\n",
       " ['FLOORSMIN_MODE', 0.13400689549697736],\n",
       " ['ELEVATORS_MODE', 0.13368144568353682],\n",
       " ['TOTALAREA_MODE', 0.13302117614934886],\n",
       " ['LIVINGAREA_MODE', 0.12531429448313444],\n",
       " ['APARTMENTS_AVG', 0.11969975175875225],\n",
       " ['AMT_CREDIT', 0.11913913175560588],\n",
       " ['APARTMENTS_MEDI', 0.11854824122994169],\n",
       " ['LIVE_CITY_NOT_WORK_CITY', 0.1150972649675867],\n",
       " ['FLAG_DOCUMENT_6', 0.11321094956498971],\n",
       " ['DEF_30_CNT_SOCIAL_CIRCLE', 0.11053498545585493],\n",
       " ['APARTMENTS_MODE', 0.11042050156010762],\n",
       " ['DEF_60_CNT_SOCIAL_CIRCLE', 0.10614979157992249],\n",
       " ['FLAG_WORK_PHONE', 0.10172393701554393],\n",
       " ['LIVINGAPARTMENTS_AVG', 0.10144767074331486],\n",
       " ['LIVINGAPARTMENTS_MEDI', 0.0996006541993235],\n",
       " ['LIVINGAPARTMENTS_MODE', 0.09445890720194784],\n",
       " ['BASEMENTAREA_AVG', 0.09415886220597067],\n",
       " ['BASEMENTAREA_MEDI', 0.0912278599869365],\n",
       " ['FLAG_PHONE', 0.08914341851770605],\n",
       " ['YEARS_BUILD_MEDI', 0.08861950809008672],\n",
       " ['HOUR_APPR_PROCESS_START', 0.08848595288944651],\n",
       " ['YEARS_BUILD_AVG', 0.08791969050344997],\n",
       " ['YEARS_BUILD_MODE', 0.08758428929869318],\n",
       " ['BASEMENTAREA_MODE', 0.0824777540034273],\n",
       " ['FLAG_OWN_CAR', 0.08125510881929147],\n",
       " ['COMMONAREA_MEDI', 0.07766956326289659],\n",
       " ['COMMONAREA_AVG', 0.07757430441188086],\n",
       " ['ENTRANCES_AVG', 0.07607635616684594],\n",
       " ['ENTRANCES_MEDI', 0.07549254033519825],\n",
       " ['AMT_REQ_CREDIT_BUREAU_YEAR', 0.07352858847681773],\n",
       " ['ENTRANCES_MODE', 0.06900437960095758],\n",
       " ['CNT_CHILDREN', 0.06893558035099098],\n",
       " ['COMMONAREA_MODE', 0.06790403657262353],\n",
       " ['NONLIVINGAREA_AVG', 0.056313612488051855],\n",
       " ['NONLIVINGAREA_MEDI', 0.0552398958272823],\n",
       " ['FLAG_DOCUMENT_13', 0.05267199351770139],\n",
       " ['NONLIVINGAREA_MODE', 0.05264106242862053],\n",
       " ['ANNUITY_INCOME_IN_PERCENTAGE', 0.05237578275545255],\n",
       " ['AMT_REQ_CREDIT_BUREAU_MON', 0.051094118605213346],\n",
       " ['AMT_ANNUITY', 0.0503138860808599],\n",
       " ['PAYMENT_RATE', 0.04851426572153408],\n",
       " ['FLAG_DOCUMENT_16', 0.04741251066299549],\n",
       " ['LANDAREA_MEDI', 0.04444878197013674],\n",
       " ['LANDAREA_AVG', 0.042792187095193834],\n",
       " ['FLAG_DOCUMENT_14', 0.04166765132500792],\n",
       " ['LANDAREA_MODE', 0.04009933214294488],\n",
       " ['YEARS_BEGINEXPLUATATION_MEDI', 0.03633498345001264],\n",
       " ['YEARS_BEGINEXPLUATATION_AVG', 0.035414495157217105],\n",
       " ['OBS_30_CNT_SOCIAL_CIRCLE', 0.03365052889526577],\n",
       " ['CNT_FAM_MEMBERS', 0.03349694998799851],\n",
       " ['OBS_60_CNT_SOCIAL_CIRCLE', 0.03326091150616586],\n",
       " ['YEARS_BEGINEXPLUATATION_MODE', 0.033235068790182294],\n",
       " ['FLAG_DOCUMENT_18', 0.03151466379298941],\n",
       " ['FLAG_DOCUMENT_8', 0.03010865030583054],\n",
       " ['FLAG_DOCUMENT_15', 0.02938577784581252],\n",
       " ['REG_REGION_NOT_WORK_REGION', 0.02495051151562479],\n",
       " ['FLAG_OWN_REALTY', 0.022473489712283433],\n",
       " ['REG_REGION_NOT_LIVE_REGION', 0.01981868105492834],\n",
       " ['FLAG_DOCUMENT_4', 0.01880915819956144],\n",
       " ['FLAG_DOCUMENT_9', 0.016949243112654444],\n",
       " ['FLAG_DOCUMENT_11', 0.016437432037364495],\n",
       " ['FLAG_DOCUMENT_17', 0.015695472576218516],\n",
       " ['INCOME_PER_PERSON', 0.014857463745504873],\n",
       " ['FLAG_DOCUMENT_2', 0.014102868169918202],\n",
       " ['NONLIVINGAPARTMENTS_AVG', 0.012659986522685216],\n",
       " ['FLAG_DOCUMENT_21', 0.012010220800320642],\n",
       " ['NONLIVINGAPARTMENTS_MEDI', 0.01094944833851889],\n",
       " ['AMT_REQ_CREDIT_BUREAU_DAY', 0.010305678924004864],\n",
       " ['LIVE_REGION_NOT_WORK_REGION', 0.010244838159278853],\n",
       " ['FLAG_DOCUMENT_10', 0.009952554101942682],\n",
       " ['AMT_REQ_CREDIT_BUREAU_QRT', 0.008302410520156319],\n",
       " ['AMT_INCOME_TOTAL', 0.008086555811248444],\n",
       " ['FLAG_EMAIL', 0.006492048240881688],\n",
       " ['FLAG_DOCUMENT_7', 0.006164232448668165],\n",
       " ['NONLIVINGAPARTMENTS_MODE', 0.00611751933020875],\n",
       " ['FLAG_DOCUMENT_12', 0.00531981689029944],\n",
       " ['FLAG_DOCUMENT_19', 0.0052196415337551665],\n",
       " ['INCOME_CREDIT_IN_PERCENTAGE ', 0.003983731239703955],\n",
       " ['FLAG_MOBIL', 0.003761671944228016],\n",
       " ['AMT_REQ_CREDIT_BUREAU_HOUR', 0.003464415567425317],\n",
       " ['AMT_REQ_CREDIT_BUREAU_WEEK', 0.002953515805353954],\n",
       " ['FLAG_CONT_MOBILE', 0.0013683339217147367],\n",
       " ['FLAG_DOCUMENT_5', 0.0011631538792419723],\n",
       " ['FLAG_DOCUMENT_20', 0.0007846239218365093]]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter features by the ones that have least distribution diff on target\n",
    "sorted_biggest_distribution_features = []\n",
    "target_groupby = df.groupby('TARGET')\n",
    "categorical_columns = []\n",
    "for (columnName, columnData) in df.iteritems():\n",
    "    if columnName == 'TARGET' or columnName == 'index':\n",
    "        continue\n",
    "    dtype = df[columnName].dtype\n",
    "    if dtype == np.float64 or dtype == np.int64:\n",
    "        means = target_groupby[columnName].mean()\n",
    "        stds = target_groupby[columnName].std()\n",
    "        avg_stds = (stds[0] + stds[1])/2\n",
    "        zero_target = means[0]\n",
    "        one_target = means[1]\n",
    "        std_diff = abs((one_target - zero_target)/avg_stds)\n",
    "        sorted_biggest_distribution_features.append([columnName, std_diff])\n",
    "    else:\n",
    "        categorical_columns.append(columnName)\n",
    "\n",
    "sorted_biggest_distribution_features.sort(key = lambda x: x[1], reverse=True)\n",
    "sorted_biggest_distribution_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ALL_EXT_SOURCE_MEAN', 'EXT_SOURCE_3', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'DAYS_EMPLOYED', 'DAYS_BIRTH', 'BIRTH_IN_YEARS', 'REGION_RATING_CLIENT_W_CITY', 'REGION_RATING_CLIENT', 'DAYS_LAST_PHONE_CHANGE', 'CODE_GENDER', 'DAYS_ID_PUBLISH', 'FLAG_EMP_PHONE', 'REG_CITY_NOT_WORK_CITY', 'FLOORSMAX_AVG', 'FLOORSMAX_MEDI', 'FLOORSMAX_MODE', 'FLAG_DOCUMENT_3', 'DAYS_REGISTRATION', 'AMT_GOODS_PRICE', 'REG_CITY_NOT_LIVE_CITY', 'REGION_POPULATION_RELATIVE', 'ELEVATORS_AVG', 'OWN_CAR_AGE', 'ELEVATORS_MEDI', 'FLOORSMIN_AVG', 'FLOORSMIN_MEDI', 'LIVINGAREA_AVG', 'LIVINGAREA_MEDI', 'FLOORSMIN_MODE', 'ELEVATORS_MODE', 'TOTALAREA_MODE', 'LIVINGAREA_MODE', 'APARTMENTS_AVG', 'AMT_CREDIT', 'APARTMENTS_MEDI', 'LIVE_CITY_NOT_WORK_CITY', 'FLAG_DOCUMENT_6', 'DEF_30_CNT_SOCIAL_CIRCLE', 'APARTMENTS_MODE', 'DEF_60_CNT_SOCIAL_CIRCLE', 'FLAG_WORK_PHONE', 'LIVINGAPARTMENTS_AVG', 'LIVINGAPARTMENTS_MEDI', 'LIVINGAPARTMENTS_MODE', 'BASEMENTAREA_AVG', 'BASEMENTAREA_MEDI', 'FLAG_PHONE', 'YEARS_BUILD_MEDI', 'HOUR_APPR_PROCESS_START', 'YEARS_BUILD_AVG', 'YEARS_BUILD_MODE', 'BASEMENTAREA_MODE', 'FLAG_OWN_CAR', 'COMMONAREA_MEDI', 'COMMONAREA_AVG', 'ENTRANCES_AVG', 'ENTRANCES_MEDI', 'AMT_REQ_CREDIT_BUREAU_YEAR', 'ENTRANCES_MODE', 'CNT_CHILDREN', 'COMMONAREA_MODE', 'NONLIVINGAREA_AVG', 'NONLIVINGAREA_MEDI', 'FLAG_DOCUMENT_13', 'NONLIVINGAREA_MODE', 'ANNUITY_INCOME_IN_PERCENTAGE', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_ANNUITY', 'PAYMENT_RATE', 'FLAG_DOCUMENT_16', 'LANDAREA_MEDI', 'LANDAREA_AVG', 'FLAG_DOCUMENT_14', 'LANDAREA_MODE', 'YEARS_BEGINEXPLUATATION_MEDI', 'YEARS_BEGINEXPLUATATION_AVG', 'OBS_30_CNT_SOCIAL_CIRCLE', 'CNT_FAM_MEMBERS', 'OBS_60_CNT_SOCIAL_CIRCLE', 'YEARS_BEGINEXPLUATATION_MODE', 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_8', 'TARGET', 'index', 'NAME_CONTRACT_TYPE', 'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'OCCUPATION_TYPE', 'WEEKDAY_APPR_PROCESS_START', 'ORGANIZATION_TYPE', 'FONDKAPREMONT_MODE', 'HOUSETYPE_MODE', 'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE']\n",
      "['NAME_CONTRACT_TYPE', 'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'OCCUPATION_TYPE', 'WEEKDAY_APPR_PROCESS_START', 'ORGANIZATION_TYPE', 'FONDKAPREMONT_MODE', 'HOUSETYPE_MODE', 'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE']\n",
      "98\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['index'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-0aa56d83067f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns_to_keep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0msub_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumns_to_keep\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0msub_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2906\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2907\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2908\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2910\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1255\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1302\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m             \u001b[1;31m# we skip the warning on Categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['index'] not in index\""
     ]
    }
   ],
   "source": [
    "columns_to_keep = list(map(lambda x: x[0], filter(lambda x: x[1] > .03, sorted_biggest_distribution_features))) + ['TARGET', 'index'] + categorical_columns\n",
    "print(columns_to_keep)\n",
    "print(categorical_columns)\n",
    "print(len(columns_to_keep))\n",
    "\n",
    "sub_df = df[columns_to_keep]\n",
    "sub_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = (sub_df.loc[sub_df['TARGET'].notnull(), :].drop(columns=['TARGET'], axis=1), \n",
    "        sub_df.loc[sub_df['TARGET'].notnull(), 'TARGET'])\n",
    "\n",
    "# test set for kaggle\n",
    "X_test = sub_df.loc[sub_df['TARGET'].isnull(), :].drop(columns=['TARGET'], axis=1)\n",
    "\n",
    "# columns for pipeline\n",
    "cat_cols = list(X.select_dtypes(include=object).columns)\n",
    "num_cols = list(X.select_dtypes(include=[int, float]).columns)\n",
    "len(cat_cols),len(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pipelines\n",
    "\n",
    "# one hot encoding \n",
    "categorical_pipe = Pipeline(steps=[\n",
    "    ('cat_imp', SimpleImputer(strategy='most_frequent', add_indicator=False)),\n",
    "  ('one_hot_encoder', OneHotEncoder(sparse=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# numerical \n",
    "numerical_pipe = Pipeline(steps=[\n",
    "    ('num_imp', SimpleImputer(strategy='median', add_indicator=False)),\n",
    "    (\"scale\", StandardScaler())  \n",
    "])\n",
    "\n",
    "\n",
    "# transform columns \n",
    "column_transformer = ColumnTransformer(transformers=[    \n",
    "    ('num_pip', numerical_pipe, num_cols),\n",
    "    ('cat_pipe', categorical_pipe, cat_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply preprocessing to X\n",
    "X_trans = column_transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smote sampling\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "X_sm, y_sm = smote.fit_resample(X_trans,y)\n",
    "\n",
    "# split data into k folds\n",
    "# sss = StratifiedShuffleSplit(n_splits=3, test_size=0.3, random_state=42)\n",
    "# score_val = []\n",
    "# for train_index, val_index in sss.split(X_sm, y_sm):\n",
    "#     # initalize model \n",
    "#     model = LogisticRegression(solver='lbfgs', random_state=42,max_iter=1000)\n",
    "#     # fit model \n",
    "#     model.fit(X_sm[train_index], y_sm[train_index])\n",
    "#     # test model\n",
    "#     score_val.append(balanced_accuracy_score(y_sm[val_index], model.predict(X_sm[val_index])))\n",
    "## takes about 6 min to execute ... 2 min per fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifaction report on training set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.69      0.69    226145\n",
      "           1       0.69      0.70      0.70    226146\n",
      "\n",
      "    accuracy                           0.70    452291\n",
      "   macro avg       0.70      0.70      0.70    452291\n",
      "weighted avg       0.70      0.70      0.70    452291\n",
      "\n",
      "--------------------------------------------------------------\n",
      "classifaction report on validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.69      0.70     56537\n",
      "           1       0.70      0.70      0.70     56536\n",
      "\n",
      "    accuracy                           0.70    113073\n",
      "   macro avg       0.70      0.70      0.70    113073\n",
      "weighted avg       0.70      0.70      0.70    113073\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_sm, y_sm, test_size=0.2, random_state= 42, stratify=y_sm)\n",
    "logreg= LogisticRegression(solver='lbfgs', random_state=42, max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_train = logreg.predict(X_train)\n",
    "y_pred_val = logreg.predict(X_val)\n",
    "print('classifaction report on training set')\n",
    "print(classification_report(y_train, y_pred_train, labels=[0,1]))\n",
    "print('--------------------------------------------------------------')\n",
    "print('classifaction report on validation set')\n",
    "print(classification_report(y_val, y_pred_val, labels=[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
