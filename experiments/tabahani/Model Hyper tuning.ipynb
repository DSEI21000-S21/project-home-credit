{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cardiac-desktop",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# classifiers  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "# sampling \n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "# useful libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "junior-control",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import dropbox\n",
    "from zipfile import ZipFile\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(''))))\n",
    "from utils.data_extract_utils import extract_zip, extract_features_from_bureau, get_clean_credit, remove_highly_correlated_columns,extract_features_from_installments_payments\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "postal-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing_data_info(df):\n",
    "    \"\"\"\n",
    "    add description .. \n",
    "    \n",
    "    \"\"\"\n",
    "    num_of_instance, _ = df.shape\n",
    "    #print(num_of_instance)\n",
    "    names = {'index': 'feature', \n",
    "             0: 'PERC_missing_data'}\n",
    "    \n",
    "    missing_df = (df.isnull() \\\n",
    "        .sum(axis=0)/num_of_instance) \\\n",
    "        .to_frame() \\\n",
    "        .reset_index() \\\n",
    "        .rename(columns=names) \\\n",
    "        .sort_values(by='PERC_missing_data', ascending=False) \\\n",
    "        .reset_index(drop=True)\n",
    "    \n",
    "    d = {}\n",
    "    # no missing \n",
    "    zero = missing_df[missing_df['PERC_missing_data'] == 0]\n",
    "    d['x = 0'] = list(zero.feature)\n",
    "    le_10 = missing_df[(missing_df['PERC_missing_data'] > 0.0) & (missing_df['PERC_missing_data'] <= 0.1)]\n",
    "    \n",
    "    d['0< x <= 25'] = list(missing_df[(missing_df['PERC_missing_data'] > 0.0) & (missing_df['PERC_missing_data'] <= 0.25)].feature)\n",
    "    \n",
    "    d['25 < x <= 50'] = list(missing_df[(missing_df['PERC_missing_data'] > 0.25) & (missing_df['PERC_missing_data'] <= 0.5)].feature)\n",
    "    \n",
    "    d['x > 50'] = list(missing_df[missing_df['PERC_missing_data'] > 0.5].feature)\n",
    "    \n",
    "    return missing_df, d\n",
    "\n",
    "def combine(x):\n",
    "    if x == \"Incomplete higher\" or x == 'Academic degree':\n",
    "        return 'Higher education'\n",
    "    elif x == 'Lower secondary':\n",
    "        return 'Secondary / secondary special'\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def get_columns_x(application, col_name, threshhold):\n",
    "    temp = application.loc[:, col_name].value_counts(dropna=False).to_frame().reset_index()\n",
    "    temp.columns = ['values', 'count']\n",
    "    temp['prec of val'] = temp['count'].apply(lambda x: x/application.shape[0])\n",
    "    groups = list(temp.loc[temp['prec of val'] <threshhold, 'values'].values)\n",
    "    \n",
    "    return groups\n",
    "\n",
    "def corr_with_target(application):\n",
    "    target = application.loc[application['TARGET'].notnull(), 'TARGET']\n",
    "    train_df = application.loc[application['TARGET'].notnull(), :].drop(columns=['TARGET']).select_dtypes(include = [int, float])\n",
    "\n",
    "    corr_col = [i for i in train_df.columns if i not in ['index', 'SK_ID_CURR']]\n",
    "    corr_arr = pd.Series([target.corr(train_df[i]) for i in corr_col])\n",
    "    \n",
    "    name = pd.Series(corr_col)\n",
    "    df_dict = {'feature': name, 'corr with target': corr_arr}\n",
    "    corr_df = pd.DataFrame(df_dict).sort_values(by = 'corr with target',ascending=False)\n",
    "    \n",
    "    return corr_df\n",
    "\n",
    "def clean_application(data):\n",
    "\n",
    "    # get table \n",
    "    application = data['application_train'].copy().append(data['application_test']).reset_index()\n",
    "    \n",
    "    # fix categorical data \n",
    "\n",
    "    # 'NAME_TYPE_SUITE'\n",
    "    application.replace({'NAME_TYPE_SUITE': ['Children', \n",
    "                                             'Other_B', \n",
    "                                             'Other_A', \n",
    "                                             'Group of people']}, \n",
    "                        'Other', inplace = True)\n",
    "\n",
    "\n",
    "    # 'NAME_INCOME_TYPE'\n",
    "    application.replace({'NAME_INCOME_TYPE': ['Unemployed', \n",
    "                                              'Student', \n",
    "                                              'Businessman', \n",
    "                                              'Maternity leave']}, \n",
    "                        'Other', inplace=True)\n",
    "\n",
    "    # NAME_EDUCATION_TYPE\n",
    "    application['NAME_EDUCATION_TYPE'] = application['NAME_EDUCATION_TYPE'].apply(lambda x: combine(x))\n",
    "\n",
    "    #'NAME_HOUSING_TYPE'\n",
    "    application.replace({'NAME_HOUSING_TYPE': ['Municipal apartment', \n",
    "                                               'Office apartment', \n",
    "                                               'Co-op apartment']}, \n",
    "                        'Rented apartment', inplace = True)\n",
    "\n",
    "    # OCCUPATION_TYPE\n",
    "    other_occp = get_columns_x(application, 'OCCUPATION_TYPE', 0.03)  \n",
    "    application.replace({'OCCUPATION_TYPE': other_occp}, \n",
    "                        'Other', inplace = True)\n",
    "\n",
    "    # ORGANIZATION_TYPE\n",
    "    other_org = get_columns_x(application, 'ORGANIZATION_TYPE', 0.02)  \n",
    "    application.replace({'ORGANIZATION_TYPE': other_org}, \n",
    "                        'Other', inplace = True)\n",
    "\n",
    "    # drop cat features - low variance and high % of missing val\n",
    "    application.drop(columns = ['FONDKAPREMONT_MODE', \n",
    "                                'HOUSETYPE_MODE', \n",
    "                                'WALLSMATERIAL_MODE', \n",
    "                                'EMERGENCYSTATE_MODE'], \n",
    "                     axis = 1, inplace=True)\n",
    "\n",
    "    ## label encoder for binary values\n",
    "    bin_features = ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']\n",
    "\n",
    "    replace_dict = {'CODE_GENDER': {'M': 0, 'F': 1},\n",
    "                    'FLAG_OWN_CAR': {'Y': 0, 'N': 1}, \n",
    "                    'FLAG_OWN_REALTY':{'Y': 0, 'N': 1},\n",
    "                   'NAME_EDUCATION_TYPE': {'Higher education': 1,\n",
    "                                          'Secondary / secondary special': 0}}\n",
    "\n",
    "    application.replace(replace_dict, inplace=True)\n",
    "\n",
    "\n",
    "    # remove few instances with low appearance\n",
    "    application = application.loc[application['CODE_GENDER'] != 'XNA', :]\n",
    "    application = application.loc[application['NAME_FAMILY_STATUS'] != 'Unknown', :]\n",
    "\n",
    "\n",
    "    # drop_features > 50% of missing vals (both: cat, num)\n",
    "    cols = [i for i in list(application.columns) if i != 'TARGET']\n",
    "    _, missing_dict = get_missing_data_info(application.loc[:,cols])\n",
    "    drop_cols = missing_dict['x > 50']\n",
    "\n",
    "    # keep EXT_SOURCE_1 --> highly corr with target \n",
    "    drop_cols.remove('EXT_SOURCE_1')\n",
    "    application.drop(columns = drop_cols, axis = 1, inplace = True)\n",
    "\n",
    "    # Numerical features \n",
    "\n",
    "    ## DAYS_EMPLOYED\n",
    "    application['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)\n",
    "    application['DAYS_EMPLOYED'] =application['DAYS_EMPLOYED'].apply(lambda x: abs(x))\n",
    "\n",
    "    application['BIRTH_IN_YEARS'] = application['DAYS_BIRTH'].apply(lambda x: abs(x)/365)\n",
    "\n",
    "\n",
    "    # add new features \n",
    "    application['ALL_EXT_SOURCE_MEAN']=application[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis = 1)\n",
    "    application['PAYMENT_RATE'] = application['AMT_ANNUITY']/application['AMT_CREDIT']\n",
    "    application['INCOME_PER_PERSON'] = application['AMT_INCOME_TOTAL']/application['CNT_FAM_MEMBERS']\n",
    "    application['INCOME_CREDIT_IN_PERCENTAGE '] = application['AMT_INCOME_TOTAL']/application['AMT_CREDIT']\n",
    "    application['ANNUITY_INCOME_IN_PERCENTAGE'] = application['AMT_ANNUITY']/application['AMT_INCOME_TOTAL']\n",
    "\n",
    "    doc_cols = [i for i in list(application.columns) if 'FLAG_DOCUMENT' in i]\n",
    "    application['ALL_FLAG_DOCUMENT_SUM']=application[doc_cols].mean(axis = 1)\n",
    "\n",
    "    ## drop indiv doc columns + other useless columns \n",
    "    application.drop(columns = doc_cols, axis = 1, inplace = True)\n",
    "    application.drop(columns = ['FLAG_CONT_MOBILE','FLAG_MOBIL', 'DAYS_BIRTH'], axis = 1, inplace = True)\n",
    "    \n",
    "\n",
    "    if 'index' in list(application.columns):\n",
    "        application.drop(columns = ['index'], axis = 1, inplace = True)\n",
    "        print('index column removed')\n",
    "\n",
    "    return application\n",
    "\n",
    "def join_tables(data):\n",
    "    # credit card table\n",
    "    cc = get_clean_credit(data['credit_card_balance'])\n",
    "    cc_agg = cc.groupby('SK_ID_CURR').agg(['min', 'max', 'mean','var'])\n",
    "    cc_agg.columns = pd.Index(list(map(lambda x: 'CC' + '_' + x[0] + '_' + x[1], list(cc_agg.columns))))\n",
    "    \n",
    "    # main aplication \n",
    "    train_test = clean_application(data)\n",
    "    train_test.set_index('SK_ID_CURR', inplace=True, drop=False)\n",
    "    \n",
    "    # burea/balance table\n",
    "    bb = extract_features_from_bureau(data['bureau'], data['bureau_balance'])\n",
    "    \n",
    "    # isntallments payments table\n",
    "    ip = extract_features_from_installments_payments(data['installments_payments'])\n",
    "    \n",
    "    # join table\n",
    "    df = pd.concat([train_test, bb, ip, cc_agg], axis=1) \n",
    "    df = df.reset_index(drop=True)\n",
    "    df['SK_ID_CURR'] = df['SK_ID_CURR'].astype('Int64')\n",
    "    \n",
    "    # clean memory\n",
    "    del cc\n",
    "    del cc_agg\n",
    "    del train_test\n",
    "    del bb\n",
    "    del ip\n",
    "    gc.collect()\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aware-planet",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbx = dropbox.Dropbox('cHV7yAR0J6YAAAAAAAAAAVQ1NLCrOwerbaNltPWHslYXKuUTJ5_wfgJsuFcmx83o')\n",
    "\n",
    "data = {}\n",
    "for entry in dbx.files_list_folder('').entries:\n",
    "    response = dbx.files_download('/{}'.format(entry.name))\n",
    "    \n",
    "    if 'zip' in entry.name:\n",
    "        content = extract_zip(response[1].content)\n",
    "    \n",
    "        for file in content:\n",
    "            df = pd.read_csv(file[1])\n",
    "            data[entry.name.replace('.csv.zip', '')] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "studied-airline",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tabahani\\Documents\\home-credit-default-risk\\utils\\data_extract_utils.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  full_trimmed['SK_DPD_SUM'] = dpd_counts_sum['SK_DPD']\n",
      "C:\\Users\\Tabahani\\Documents\\home-credit-default-risk\\utils\\data_extract_utils.py:91: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  full_trimmed['SK_DPD_DEF_SUM'] = dpd_df_counts_sum['SK_DPD_DEF']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index column removed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(356254, 104)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df = join_tables(data)\n",
    "main_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daily-growth",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = (main_df.loc[(main_df['TARGET'].notnull()) & (main_df['SK_ID_CURR'].notnull()), :].drop(columns=['TARGET', 'SK_ID_CURR'], axis=1), \n",
    "        main_df.loc[(main_df['TARGET'].notnull()) & (main_df['SK_ID_CURR'].notnull()), 'TARGET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "oriental-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = list(X.select_dtypes(include=object).columns)\n",
    "num_cols = list(X.select_dtypes(include=[int, float]).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "irish-nation",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_pipe = Pipeline(steps=[\n",
    "    ('cat_imp', SimpleImputer(strategy='most_frequent', add_indicator=False)),\n",
    "  ('one_hot_encoder', OneHotEncoder(sparse=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# numerical \n",
    "numerical_pipe = Pipeline(steps=[\n",
    "    ('num_imp', SimpleImputer(strategy='median', add_indicator=False)),\n",
    "    (\"scale\", StandardScaler())  \n",
    "])\n",
    "\n",
    "\n",
    "# transform columns \n",
    "column_transformer = ColumnTransformer(transformers=[    \n",
    "    ('num_pip', numerical_pipe, num_cols),\n",
    "    ('cat_pipe', categorical_pipe, cat_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "royal-ambassador",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trans = column_transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "veterinary-advocacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy='minority')\n",
    "X_sm, y_sm = smote.fit_resample(X_trans,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sixth-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_sm, y_sm, test_size=0.2, random_state= 42, stratify=y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "timely-cardiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(random_state=0,solver='sag')\n",
    "linearSVM = svm.LinearSVC()\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "spare-knife",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import loguniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "space ={\n",
    "}\n",
    "\n",
    "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "space['penalty'] = ['l1', 'l2', 'elasticnet']\n",
    "space['C'] = loguniform.rvs(1e-5, 1e0, size=10)\n",
    "\n",
    "search = RandomizedSearchCV(LogisticRegression(),space,n_jobs=-1,scoring='accuracy')\n",
    "\n",
    "result = search.fit(X_train,y_train)\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-auction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
