{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T05:53:37.726479Z",
     "start_time": "2021-05-11T05:53:21.131018Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/Users/eyobmanhardt/opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "# sklearn utilties \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# classifiers  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.dummy import DummyClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# sampling \n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "# useful libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# more lib\n",
    "import os, sys\n",
    "import dropbox\n",
    "from zipfile import ZipFile\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(''))))\n",
    "from utils.data_extract_utils import extract_zip, extract_features_from_bureau, get_clean_credit, remove_highly_correlated_columns,extract_features_from_installments_payments\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T06:02:23.171119Z",
     "start_time": "2021-05-11T06:02:23.123608Z"
    }
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def get_missing_data_info(df):\n",
    "    \"\"\"\n",
    "    add description .. \n",
    "    \n",
    "    \"\"\"\n",
    "    num_of_instance, _ = df.shape\n",
    "    #print(num_of_instance)\n",
    "    names = {'index': 'feature', \n",
    "             0: 'PERC_missing_data'}\n",
    "    \n",
    "    missing_df = (df.isnull() \\\n",
    "        .sum(axis=0)/num_of_instance) \\\n",
    "        .to_frame() \\\n",
    "        .reset_index() \\\n",
    "        .rename(columns=names) \\\n",
    "        .sort_values(by='PERC_missing_data', ascending=False) \\\n",
    "        .reset_index(drop=True)\n",
    "    \n",
    "    d = {}\n",
    "    # no missing \n",
    "    zero = missing_df[missing_df['PERC_missing_data'] == 0]\n",
    "    d['x = 0'] = list(zero.feature)\n",
    "    le_10 = missing_df[(missing_df['PERC_missing_data'] > 0.0) & (missing_df['PERC_missing_data'] <= 0.1)]\n",
    "    \n",
    "    d['0< x <= 25'] = list(missing_df[(missing_df['PERC_missing_data'] > 0.0) & (missing_df['PERC_missing_data'] <= 0.25)].feature)\n",
    "    \n",
    "    d['25 < x <= 50'] = list(missing_df[(missing_df['PERC_missing_data'] > 0.25) & (missing_df['PERC_missing_data'] <= 0.5)].feature)\n",
    "    \n",
    "    d['x > 50'] = list(missing_df[missing_df['PERC_missing_data'] > 0.5].feature)\n",
    "    \n",
    "    return missing_df, d\n",
    "\n",
    "def combine(x):\n",
    "    if x == \"Incomplete higher\" or x == 'Academic degree':\n",
    "        return 'Higher education'\n",
    "    elif x == 'Lower secondary':\n",
    "        return 'Secondary / secondary special'\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def get_columns_x(col_name, threshhold):\n",
    "    temp = application.loc[:, col_name].value_counts(dropna=False).to_frame().reset_index()\n",
    "    temp.columns = ['values', 'count']\n",
    "    temp['prec of val'] = temp['count'].apply(lambda x: x/application.shape[0])\n",
    "    groups = list(temp.loc[temp['prec of val'] <threshhold, 'values'].values)\n",
    "    \n",
    "    return groups\n",
    "\n",
    "def corr_with_target(application):\n",
    "    target = application.loc[application['TARGET'].notnull(), 'TARGET']\n",
    "    train_df = application.loc[application['TARGET'].notnull(), :].drop(columns=['TARGET']).select_dtypes(include = [int, float])\n",
    "\n",
    "    corr_col = [i for i in train_df.columns if i not in ['index', 'SK_ID_CURR']]\n",
    "    corr_arr = pd.Series([target.corr(train_df[i]) for i in corr_col])\n",
    "    \n",
    "    name = pd.Series(corr_col)\n",
    "    df_dict = {'feature': name, 'corr with target': corr_arr}\n",
    "    corr_df = pd.DataFrame(df_dict).sort_values(by = 'corr with target',ascending=False)\n",
    "    \n",
    "    return corr_df\n",
    "\n",
    "def clean_application(data):\n",
    "\n",
    "    # get table \n",
    "    application = data['application_train'].copy().append(data['application_test']).reset_index()\n",
    "    \n",
    "    # fix categorical data \n",
    "\n",
    "    # 'NAME_TYPE_SUITE'\n",
    "    application.replace({'NAME_TYPE_SUITE': ['Children', \n",
    "                                             'Other_B', \n",
    "                                             'Other_A', \n",
    "                                             'Group of people']}, \n",
    "                        'Other', inplace = True)\n",
    "\n",
    "\n",
    "    # 'NAME_INCOME_TYPE'\n",
    "    application.replace({'NAME_INCOME_TYPE': ['Unemployed', \n",
    "                                              'Student', \n",
    "                                              'Businessman', \n",
    "                                              'Maternity leave']}, \n",
    "                        'Other', inplace=True)\n",
    "\n",
    "    # NAME_EDUCATION_TYPE\n",
    "    application['NAME_EDUCATION_TYPE'] = application['NAME_EDUCATION_TYPE'].apply(lambda x: combine(x))\n",
    "\n",
    "    #'NAME_HOUSING_TYPE'\n",
    "    application.replace({'NAME_HOUSING_TYPE': ['Municipal apartment', \n",
    "                                               'Office apartment', \n",
    "                                               'Co-op apartment']}, \n",
    "                        'Rented apartment', inplace = True)\n",
    "\n",
    "    # OCCUPATION_TYPE\n",
    "    other_occp = get_columns_x('OCCUPATION_TYPE', 0.03)  \n",
    "    application.replace({'OCCUPATION_TYPE': other_occp}, \n",
    "                        'Other', inplace = True)\n",
    "\n",
    "    # ORGANIZATION_TYPE \n",
    "    application.replace({'ORGANIZATION_TYPE': other_org}, \n",
    "                        'Other', inplace = True)\n",
    "\n",
    "    # drop cat features - low variance and high % of missing val\n",
    "    application.drop(columns = ['FONDKAPREMONT_MODE', \n",
    "                                'HOUSETYPE_MODE', \n",
    "                                'WALLSMATERIAL_MODE', \n",
    "                                'EMERGENCYSTATE_MODE'], \n",
    "                     axis = 1, inplace=True)\n",
    "\n",
    "    ## label encoder for binary values\n",
    "    bin_features = ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']\n",
    "\n",
    "    replace_dict = {'CODE_GENDER': {'M': 0, 'F': 1},\n",
    "                    'FLAG_OWN_CAR': {'Y': 0, 'N': 1}, \n",
    "                    'FLAG_OWN_REALTY':{'Y': 0, 'N': 1},\n",
    "                   'NAME_EDUCATION_TYPE': {'Higher education': 1,\n",
    "                                          'Secondary / secondary special': 0}}\n",
    "\n",
    "    application.replace(replace_dict, inplace=True)\n",
    "\n",
    "\n",
    "    # remove few instances with low appearance\n",
    "    application = application.loc[application['CODE_GENDER'] != 'XNA', :]\n",
    "    application = application.loc[application['NAME_FAMILY_STATUS'] != 'Unknown', :]\n",
    "\n",
    "\n",
    "    # drop_features > 50% of missing vals (both: cat, num)\n",
    "    cols = [i for i in list(application.columns) if i != 'TARGET']\n",
    "    _, missing_dict = get_missing_data_info(application.loc[:,cols])\n",
    "    drop_cols = missing_dict['x > 50']\n",
    "\n",
    "    # keep EXT_SOURCE_1 --> highly corr with target \n",
    "    drop_cols.remove('EXT_SOURCE_1')\n",
    "    application.drop(columns = drop_cols, axis = 1, inplace = True)\n",
    "\n",
    "    # Numerical features \n",
    "\n",
    "    ## DAYS_EMPLOYED\n",
    "    application['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)\n",
    "    application['DAYS_EMPLOYED'] =application['DAYS_EMPLOYED'].apply(lambda x: abs(x))\n",
    "\n",
    "    application['BIRTH_IN_YEARS'] = application['DAYS_BIRTH'].apply(lambda x: abs(x)/365)\n",
    "\n",
    "\n",
    "    # add new features \n",
    "    application['ALL_EXT_SOURCE_MEAN']=application[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis = 1)\n",
    "    application['PAYMENT_RATE'] = application['AMT_ANNUITY']/application['AMT_CREDIT']\n",
    "    application['INCOME_PER_PERSON'] = application['AMT_INCOME_TOTAL']/application['CNT_FAM_MEMBERS']\n",
    "    application['INCOME_CREDIT_IN_PERCENTAGE '] = application['AMT_INCOME_TOTAL']/application['AMT_CREDIT']\n",
    "    application['ANNUITY_INCOME_IN_PERCENTAGE'] = application['AMT_ANNUITY']/application['AMT_INCOME_TOTAL']\n",
    "\n",
    "    doc_cols = [i for i in list(application.columns) if 'FLAG_DOCUMENT' in i]\n",
    "    application['ALL_FLAG_DOCUMENT_SUM']=application[doc_cols].mean(axis = 1)\n",
    "\n",
    "    ## drop indiv doc columns + other useless columns \n",
    "    application.drop(columns = doc_cols, axis = 1, inplace = True)\n",
    "    application.drop(columns = ['FLAG_CONT_MOBILE','FLAG_MOBIL', 'DAYS_BIRTH'], axis = 1, inplace = True)\n",
    "    \n",
    "\n",
    "    if 'index' in list(application.columns):\n",
    "        application.drop(columns = ['index'], axis = 1, inplace = True)\n",
    "        print('index column removed')\n",
    "\n",
    "    return application\n",
    "\n",
    "def join_tables(data):\n",
    "    \n",
    "#     train_test = clean_application(data)\n",
    "#     # join tables: bureau, bureau_balance - 1 min to execute\n",
    "    \n",
    "#     bb = extract_features_from_bureau(data['bureau'], data['bureau_balance'])\n",
    "#     ip = extract_features_from_installments_payments(data['installments_payments'])\n",
    "\n",
    "#     # Join Bureau(s) and Application tables\n",
    "#     train_test.set_index('SK_ID_CURR', inplace=True, drop=False)\n",
    "#     df = pd.concat([train_test, bb, ip], axis=1)    \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T06:04:41.957944Z",
     "start_time": "2021-05-11T06:02:28.967586Z"
    }
   },
   "outputs": [],
   "source": [
    "# Connect to dropbox\n",
    "dbx = dropbox.Dropbox('cHV7yAR0J6YAAAAAAAAAAVQ1NLCrOwerbaNltPWHslYXKuUTJ5_wfgJsuFcmx83o')\n",
    "\n",
    "data = {}\n",
    "for entry in dbx.files_list_folder('').entries:\n",
    "    response = dbx.files_download('/{}'.format(entry.name))\n",
    "    \n",
    "    if 'zip' in entry.name:\n",
    "        content = extract_zip(response[1].content)\n",
    "    \n",
    "        for file in content:\n",
    "            df = pd.read_csv(file[1])\n",
    "            data[entry.name.replace('.csv.zip', '')] = df\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T06:09:11.847972Z",
     "start_time": "2021-05-11T06:09:07.471235Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['MONTHS_BALANCE', 'AMT_BALANCE', 'AMT_CREDIT_LIMIT_ACTUAL',\\n       'AMT_RECEIVABLE_PRINCIPAL', 'AMT_TOTAL_RECEIVABLE',\\n       'NAME_CONTRACT_STATUS_Completed', 'SK_ID_CURR', 'SK_DPD', 'SK_DPD_DEF'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f67e6fb94082>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_clean_credit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'credit_card_balance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/applied_ml_final_project/project-home-credit/utils/data_extract_utils.py\u001b[0m in \u001b[0;36mget_clean_credit\u001b[0;34m(df_credit_raw)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mfull_dummies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_credit_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'NAME_CONTRACT_STATUS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0mfull_trimmed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_dummies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0museful\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mdpd_counts_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_trimmed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SK_ID_CURR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SK_DPD'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mdpd_df_counts_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_trimmed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SK_ID_CURR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SK_DPD_DEF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2910\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2911\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2912\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2914\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['MONTHS_BALANCE', 'AMT_BALANCE', 'AMT_CREDIT_LIMIT_ACTUAL',\\n       'AMT_RECEIVABLE_PRINCIPAL', 'AMT_TOTAL_RECEIVABLE',\\n       'NAME_CONTRACT_STATUS_Completed', 'SK_ID_CURR', 'SK_DPD', 'SK_DPD_DEF'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "cc = get_clean_credit('credit_card_balance')\n",
    "cc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pipelines\n",
    "\n",
    "# one hot encoding \n",
    "categorical_pipe = Pipeline(steps=[\n",
    "    ('cat_imp', SimpleImputer(strategy='most_frequent', add_indicator=False)),\n",
    "  ('one_hot_encoder', OneHotEncoder(sparse=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# numerical \n",
    "numerical_pipe = Pipeline(steps=[\n",
    "    ('num_imp', SimpleImputer(strategy='median', add_indicator=False)),\n",
    "    (\"scale\", StandardScaler())  \n",
    "])\n",
    "\n",
    "\n",
    "# transform columns \n",
    "column_transformer = ColumnTransformer(transformers=[    \n",
    "    ('num_pip', numerical_pipe, num_cols),\n",
    "    ('cat_pipe', categorical_pipe, cat_cols)\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
